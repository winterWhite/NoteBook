## 第一课：Quick Start

访问网站的过程，HTTP都做了什么？    

- 输入网址（web客户端发送HTTP请求报文，在地址栏输入的内容叫做URI，通常情况下都使用的是URL这种类型的地址，地址的内容包括了协议名称、web服务器名称、资源地址）
- 等待网站响应（通常情况下这个过程是比较短暂的，但web服务器却做的不少）
	- web服务器接收到请求以后，通过URL地址照到对应的资源，然后发送HTTP响应报文，响应的内容有：响应状态码、资源类型（MIME）、资源长度、资源内容。。。
	- web客户端接收响应信息，根据其中的资源类型对资源进行解析，并按照其格式显示为网页或其他资源类型
	
整个过程中，涉及到的知识：URL、HTTP状态码、MIME格式

一个单独的网页，通常情况下会有多个HTTP请求，包括HTML页面请求、页面的内嵌资源：如js、css文件、图片文件、视频音频文件等等    

HTTP报文只有两种：请求报文、响应报文；两种报文都是由简单的字符串组成，分为以下三个部分：

- 起始行（即报文的第一行）
	- 对于请求报文，起始行用于说明要做什么（HTTP方法、请求内容）
	- 对于响应报文，起始行用于说明出现了什么情况（响应状态码）
- 首部字段（起始行后面跟着的0个或多个名值对，用冒号分隔；首部以一个空行结束）
- 主体
	- 请求报文：要发送给服务器的数据（对于get请求就没有此内容）
	- 响应报文：返回给客户端的数据（可以是任何类型的文件，如HTML、Txt）

HTTP报文的转送——TCP/IP协议，HTTP协议建立在TCP协议之上，也就是说，在发送HTTP报文之前，web客户端与web服务器之间会通过URL建立一条TCP连接，建立的过程运用到DNS域名服务器解析。

使用Telnet命令建立TCP链接并测试HTTP请求的响应内容，模拟HTTP客户端。

web应用程序（除web浏览器、web服务器之外的）

- 代理（位于客户端和服务器之间，接收所有客户端的HTTP请求并转发给服务器，也就是代表客户端与服务器进行通信，代理可对请求和响应进行过滤）
- 缓存（将经过代理请求的文档复制保存起来，下一次访问时可直接访问副本）
- 网关（可将HTTP流量转换为其他协议）
- 隧道（对原始信息进行盲转发，通常用于加密）
- Agent代理（代表用户发起HTTP协议的应用程序，比如web浏览器、网络爬虫就是一种Agent代理）

## 第二课：URL

URL作为URI的一个子集，它主要通过资源的位置来进行标识资源；URI的另一个比较主要的子集URN则是通过名字来进行识别。

URL可分为三个部分：

- URL方案：此部分告知web客户端怎样访问资源，即使用什么协议，对于HTTP访问则是HTTP协议
- 服务器位置：此部分告知web客户端资源位于何处，可以是服务器域名也可以是IP地址
- 资源路径：此部分告知web客户端资源所在服务器本地的具体路径

具体来说：方案+主机+路径    
同时URL也可以通过其他的协议来访问资源。

URL语法:

<pre>
	方案://用户名:密码@主机:端口/路径;参数?查询字符串#页面片段
</pre>

对于HTTP协议，常用的是“主机:端口”、“路径:参数”、“查询字符串”、“页面片段”

URL的快捷方式：相对URL（在资源内部使用），关于如何在绝对URL和相对URL之间进行切换，需要涉及到基础URL，基础URL的位置有两种提供方式：
	
- 资源中显示提供：通过<base>标签指定页面中所有相对URL的基础URL
- 封装资源的基础URL：当没有显示指定时，一般将该资源的所属资源的URL作为基础URL
- 无基础URL：此时则会出现问题，该URL无效

相对URL的解析过程可用如下的流程图解释：
![](./URL.png)

自动扩展URL功能：

- 主机名扩展
- 历史扩展

URL编码机制：ASCII码+转义字符，转义字符用来表示不安全字符，同时有一些被保留受限的一些字符：
![](./URL1.png)

## 第三课：HTTP报文

请求报文的语法格式：

	<方法> <请求URL> <版本>
	<首部信息>
	<主体信息>

响应报文的语法格式：

	<版本> <状态码> <原因短语>
	<首部>
	<主体>

常用的**HTTP方法**：

- GET：从服务器获取资源
- POST：向服务器发送数据
- PUT：将主体信息储存在服务器
- DELETE：从服务器删除资源
- OPTIONS：决定可以在服务器执行哪些方法
- HEAD：只从服务器获取文档的首部
- Trace：追踪

并不是所有的浏览器都实现了衣裳的几种方法。在这些方法中，GET和HEAD方法被视为安全方法，即不会在HTTP服务器产生什么影响，GET和HEAD的区别就在于，HEAD请求的响应只返回首部的内容，而不返回主体。

使用HEAD请求的作用有：

- 在不获取资源的情况下查看资源的相关信息
- 通过查看响应码判定资源是否存在
- 通过查看首部测试资源是否被修改

除这些HTTP方法外，HTTP还支持扩展方法，可以自己编写HTTP扩展方法实现一些现有HTTP标准方法所不能实现的功能，如MOVE方法可以移动服务器资源

HTTP**响应状态码**：
![](./status.png)
最常见的两种状态码：200（成功）、404（NOT FOUND）

100 continue状态码用于当客户端想要向服务器端发送大容量的主体时才使用，且只有HTTP1.1版本才支持此状态

300重定向状态码，通过响应报文的location首部可告知资源的新位置

400范围为客户端错误状态码，500范围为服务器端错误状态码

**HTTP首部**字段：向请求信息或响应信息添加一些附加说明的内容，一般以名值对的形式出现，首部可分为通用首部（请求报文和响应报文都有的，如DATE）、请求首部、响应首部、实体首部、扩展首部，

常用的首部有：Date、Content-length、Content-type（用于描述实体内容，为实体首部）、Accept（客户端希望接受什么类型的资源，请求首部）

请求首部分为：Accept首部、条件请求首部、安全请求首部、代理请求首部    
响应请求首部：协商首部、安全响应首部    
实体首部：内容首部（content系列）、实体缓存首部

## 第四课：连接管理

HTTP连接是HTTP报文传输的关键通道，在编写HTTP应用程序时必须对此有深刻的理解。几乎所有的HTTP连接都是TCP链接，TCP连接是因特网上的可靠连接。从浏览器接收到用户输入的网址时，首先要建立TCP连接，其过程分为以下几个步骤：

- 从URL中解析主机名
- 查询主机名的IP地址（DNS）
- 获取端口号（默认为80）
- 发起到某IP的某端口的连接
- 浏览器发送HTTP请求报文
- 浏览器读取HTTP响应报文
- 关闭连接

TCP为HTTP提供一条可靠的的比特传输管道，使得从TCP一端输入的字节在另一端以原有的顺序正确的传送出来。TCP数据又是通过IP分组的小数据块来发送的，因此整个协议栈即HTTP over TCP over IP，HTTP的安全版本HTTPs就是在HTTP与TCP的中间插入了一层（TLS或SSL）的密码加密层。

TCP通过四个值识别应用程序：
<源IP地址> <源端口号> <目的IP地址> <目的端口号>    
这四个值唯一标志了一条TCP连接，两个不同的连接不可能四个值都相同。

TCP套接字编程：
![](./TCP.png)

HTTP连接的性能问题：HTTP位于TCP端的上层，因此TCP端的性能问题会直接影响到HTTP的性能，对于一次HTTP连接来说，产生的时延主要有以下几种情况：

- 查询服务器IP地址和端口号的时延（DNS）
- 建立TCP连接的时延
- 服务器处理报文的时延
- 服务器会送报文的时延

TCP握手时延：当小的HTTP事务会在TCP握手时延上耽搁过多的时间

**HTTP连接处理**：

HTTP的Connection首部：通过一个由逗号分隔的连接标签列表来为连接指定一些不会传播到其他连接中去的选项，这些标签可分为下列3类：

- HTTP首部字段名，列出只与此连接有关的首部，转发之前必须删除列出的首部
- 任意标签值，用于描述此连接的非标准选项
- 值close，说明操作完成之后须关闭这条持久链接

串行连接会将时延叠加起来，因此性能极差，以下几种方法可以提高HTTP连接性能：

- 并行连接：如加载一个页面时，并行发起几个连接分别用于请求HTML页面以及内嵌的一些资源。并行连接的缺点：占用内存，在网速较慢时不一定就比串行速度快，TCP慢启动的存在使得新连接的传输速度慢，可打开的并行连接数量是有限的。
- 持久连接：在事务处理结束后仍然保持TCP连接，缺点：可能导致大量空闲连接（Keep-Alive）通过Connection：Keep-Alive首部可请求一条连接保持在打开状态，如果服务器端可以打开一条持久连接则在响应报文的首部加上Connection：Keep-Alive。Keep-Alive选项：timeout，keep-alive响应首部中服务器希望将连接保持活跃的时间；max，希望为多少事务保持连接活跃。Keep-Alive选项是可选的，只有在Connection：Keep-Alive首部存在时才可用。
- 管道化连接：管道化连接是建立在持久连接上的，如果不能保证是持久连接就不能请求管道化连接
- 复用连接

连接的关闭：

- 任意解除连接，这种情况可能发生在资源传输尚未完成时，此时就要依靠响应报文中的Content-length首部进行判定是否资源是完整的，所以每条HTTP响应报文都应该有精确的Content-length首部。

	事务分为幂等和非幂等，幂等的事务表示不论执行多少次，结果都相同，而非幂等则相反。客户端不应该以管道化方式传送非幂等的事务请求。

- 正常关闭连接，TCP连接有两条信道（输入和输出），使用套接字调用close方法会将两条信道都关闭，成为完全关闭；也可调用shutdown方法关闭其中的一条，称为半关闭。关闭连接的输出信道相对安全，而关闭输入信道则比较危险。

	要实现正常关闭，一般应首先关闭输出信道，然后等待它的另一端关闭其输出信道，然后再完全关闭

## 第五课：Web服务器

Web服务器的形式：

- 可安装在系统上的软件web服务器（如Apache、iPlanet）
- web服务器设备（一台预先安装好服务器软件的计算机）
- 计算机芯片嵌入式web服务器（一般潜入消费类产品，如打印机）

web服务器会做什么：

- 建立连接——接受客户端连接或关闭连接
- 接收请求——从网络中读取HTTP请求报文
- 处理请求——对请求报文进行解释，并采取行动
- 访问资源——访问报文中指定的资源
- 构建响应——创建带有正确首部的HTTP响应报文
- 发送响应——将响应发送给客户端
- 记录事务处理过程——将已完成的事务记录在日志中

新连接的建立：建立连接——判断客户端IP——添加至连接列表——监视连接

服务器的分类：

- 单线程的web服务器：一次只处理一个事务知道结束
- 多进程/多线程的web服务器
- 复用I/O的服务器
- 复用的多线程web服务器

资源映射：web服务器是一种资源服务器，它负责发送预先创建好的或者动态生成的内容，在发送资源以前web服务器要通过URI将请求内容映射为web服务器上的内容或内容生成器。web服务器支持多种资源映射，最简单的一种就是通过URI指定的文件名对web服务器上的文件进行访问。

docroot：web服务器有一个专门的文件夹用于存放web内容，这个文件夹叫做docroot（文档根目录），web服务器从请求报文中获取URI并将其附加在docroot后面。通过配置DocumentRoot可以设置web服务器的虚拟托管根目录。

目录列表：当URI解析为一个目录而非一个文件时，web服务器的处理可有一下几种

- 返回一个错误
- 不反悔目录，返回一个特殊“索引文件”
- 扫描目录，返回一个目录HTML页面（该目录中的文件及其链接，可通过设置禁止）
- 返回该目录中index.html或者index.htm的文件，也可以通过设置来改变这一默认文件名

响应报文：MIME类型的确定，通过扫描文件的扩展名来确定其MIME类型；除此之外还有：魔法分类、显示分类、类型协商。

重定向响应：响应报文首部包含location字段，说明替代URI或优选URI，通常重定向的情况有如下几种

- 永久删除的资源：状态码301
- 临时删除的资源：状态码303或307
- URL增强：状态码303或307
- 负载均衡：状态码303或307
- 服务器关联：303或307
- 规范目录名称

## 第六课：代理（网络的中间实体）

web代理服务器既是web服务器又是web客户端，与web客户端交流时它扮演web服务器的角色，与web服务器交流时它扮演的是web客户端的角色，因此它应该具有发送请求报文和接收和处理请求报文并返回响应报文的能力。

代理的分类：

- 公共代理
- 私有代理

代理与网关的区别：代理连接的是使用相同协议的应用程序，而网关连接的是使用不同协议的端点，扮演的是“协议转换器”的角色

代理的作用：

- 儿童过滤器
- 文档访问控制
- 安全防火墙
- web缓存
- 反向代理
- 内容路由器
- 转码器
- 匿名者
	- 从User-Agent首部删除用户计算机与OS类型
	- 删除From首部以保护用户Email地址
	- 删除Referer首部以掩盖用户的访问痕迹
	- 删除Cookie首部以剔除概要信息和身份数据

代理部署：

- 出口代理：将代理固定在本地网络的出口点，以控制本地网络与大型因特网之间的流量，起到防火墙、过滤器或提高因特网流量的作用。
- 访问（入口）代理：放置于ISP访问点上，处理客户的聚合请求，起到缓存提高速度的作用。
- 反向代理：部署在网络边缘，作为web服务器的替代物使用，可提高web服务器的安全特性和性能。
- 网络交换代理：放置于网络之间的因特网对等交换点上，通过缓存可减轻因特网节点的拥塞。

代理的层次结构：下一个入口代理（靠近服务器）被称为父代理，下一个出口代理（靠近客户端）被称为子代理。

客户端流量流向代理的几种情况：

- 修改客户端
- 修改网络
- 修改DNS命名空间
- 修改web服务器

代理配置：

- 手工配置
- 预先配置浏览器
- 代理的自动配置
- WPAD的代理发现

代理请求的问题：

- 客户端向服务器和代理发送请求报文时的URI是不同的，在想服务器直接发送时URI只为部分URI（没有方案和主机名），而向代理发送时则是完整的URI
- 缺少“方案/主机/端口”：请求报文需要完整的URI
- 拦截代理会收到部分URI，如反向代理；
- 代理既可以处理代理请求，也可以处理服务器请求
	![](./proxy.png)
- 转发过程中对URI的修改
- URI客户端自动扩展和主机名解析
	- 没有代理时URI的解析
	![](./proxy2.png)
	- 有显示代理时的URI解析
	![](./proxy3.png)
	- 有拦截代理时的URI解析
	![](./proxy4.png)

追踪报文：

- via首部列出了报文途径的每个中间节点（代理或网关）的相关信息，其包含一个由逗号分隔的路标，每个路标都代表一个代理服务器或网关；每个路标最多包含4个组件：可选的协议名（默认HTTP）、必填的协议版本、必选的节点名、可选的描述性注释。请求报文的via首部通常情况下会与响应报文的via首部相反。
- Server首部对原始服务器使用的软件进行了描述。
- TRACE方法：
	![](./TRACE.png)

代理认证：

## 第七课：缓存

缓存的优点：

- 减少冗余的数据传输，节省网络费用
- 缓解了网络瓶颈问题，不需要更多的宽带就可以更快地加载页面
- 降低了对原始服务器的要求，服务器可以更快地响应，避免过载
- 降低了距离时延

HTTP再验证：原始服务器的内容会发生变化，缓存要不时对其进行检测，看他们保存的副本是否是服务器上最新的版本，又称为“新鲜度检测”，验证时会向原始服务器发送一个小的再验证请求，如果内容没有变化则服务器会以一个小的304 Not Modified进行响应。验证方式最常见的就是给GET请求添加If-Modified-Since首部，服务器收到此请求的响应情况有如下三种：

1. 再验证命中：响应304 Not Modified
2. 再验证未命中：响应一条完整的带有内容的 200 OK响应
3. 对象被删除：回送一个404 Not Found响应

成功的再验证比缓存未命中要快，失败的再验证几乎与未命中速度一样。

*缓存命中率*    
	由缓存提供服务的请求所占比例成为缓存命中率。    
*字节命中率*    
	缓存提供的字节在传输的所有字节中所占的比例。    

以上两种指标用于评估缓存性能。

区分缓存命中与未命中：使用Date首部，将Date首部与当前时间进行比较，如果响应中的时间较早通常可以认为这是缓存命中；同时也可以使用Age首部进行判断。

缓存的分类：私有缓存、公有缓存（或称代理缓存）

代理缓存具有拓扑结构：层次型、网状

*缓存的处理步骤*

1. 接收——缓存从网络中读取请求报文
2. 解析——从报文提取URI以及各种首部
3. 查询——查看是否有本地副本，如果没有则获取一份副本并保存在本地
4. 新鲜度检测——查看已缓存副本是否新鲜，如果不是则询问服务器是否有更新
5. 创建响应——使用新的首部和已缓存的主体构建一条响应报文
6. 发送——缓存通过网络将响应报文发送给客户端
7. 日志——缓存可选地创建一条日志来描述这一事务
![](./cache.png)

*保持副本的新鲜*

![](./cache1.png)缓存Get请求的过程

- 文档过期：通过特殊的HTTP Cache-Control首部和Expires首部说明副本的“保质期”，在规定的保质期内可以随意的使用副本而无须向服务器进行确认，一旦超过保质期则需要向服务器确认最新的副本。    
	Cache-Control：max-age定义了文档的最大生存期，以秒为单位    
	Expires：指定一个绝对的过期日期
- 服务器再验证：已过期的文档不一定就与服务器上的文档有差异，因此需要验证，如果验证发现文档内容发生了变化则获取一份新的副本并将其存在旧文档的位置上发送给客户端；如果验证发现没有变化，只需要获取新的首部，包括一个新的过期日期并对缓存中的首部进行更新即可。
- GET条件方法实现再验证：两个最有用的条件方法首部If-Modified-Since：<date>以及If-None-Match：<tags>
	- If-Modified-Since：Date再验证，此类验证请求又称为IMS请求。如果自指定日期后文档被修改了，If-Modified-Since条件则为真，GET请求就会成功执行并携带新首部新文档被返回给缓存，新首部还包含一个新的过期日期；否则条件为假，返回304，只返回响应首部而不返回主体部分
	- If-None-Match：Tags实体标签再验证，实体标签是附加到文档上的任意标签，当发布者对文档进行修改时可以同时修改这些实体标签来说明。此类验证通过对比实体标签来查看文档是否被修改了。

强弱验证器：弱验证器允许文档被少量修改而不更改缓存副本。

*缓存能力的控制：*

- no-Store & no-Cache首部：这两个首部用于防止缓存提供未经证实的已缓存对象，其中no-Store的响应会禁止缓存对响应进行复制；no-Cache的响应虽然可以缓存在本地，但必须经过新鲜度再验证之后才可以提供给客户端
- max-age首部：规定保质期
- Expires首部：规定绝对过期时间
- must-revalidate首部：告诉缓存在没有跟原始服务器进行验证的情况下不能提供这个对象的陈旧副本
- 试探性过期：当没有max-age和Expires首部时，缓存会计算出一个试探性的最大使用期。常见的算法有LM-Factor算法
- 客户端的新鲜度控制：强制刷新Refresh和重载Reload

*缓存控制设置：* 略

## 第八课：集成点 ：网关、隧道、中继

###网关：连接HTTP及其他协议和应用程序的接口

网关是资源与应用程序之间的粘合剂，可以像数据库发送查询语句，也可以生成动态内容，也可以自动将HTTP流量转化为其它协议。

web网关通常在一侧使用HTTP协议，在另一侧使用其它协议，通常可以描述为如下形式：

	<客户端协议>/<服务器端协议>

通常网关可分为：

1. 服务器端网关：通过HTTP与客户端对话，通过其他协议与服务器通信(HTTP/*)
2. 客户端网关：通过其他协议与客户端对话，通过HTTP协议与服务器通信(*/HTTP)

将HTTP流量导向网关的方法与将流量导向代理的方法一样，可以显示地配置浏览器使用网关，或者将网关配置为替代者。

各种web网关介绍：

1. HTTP/*：服务器端web网关——当请求流入原始服务器时，网关将客户端的HTTP请求转化为其他协议。
2. HTTP/HTTPS：服务器端安全网关——对所有的输入请求加密
3. HTTPS/HTTP：客户端安全加速器网关——接收安全HTTPS流量并进行解密，然后向服务器发送普通HTTP请求

资源网关介绍：

1. 通用网关接口CGI：用于装载程序以响应对特定URL的HTTP请求，并收集程序的输出数据，将其放在HTTP响应中回送。

###隧道：使HTTP应用程序访问到非HTTP协议的应用程序

HTTP隧道的建立：CONNECT方法
![](./CONNECT.png)
CONNECT方法与其他HTTP方法类似。

* SSL隧道

###中继：没有完全遵守HTTP规范的简单HTTP代理

中继用于处理HTTP中建立连接的部分，对字节进行盲转发

## 第九课：Web机器人

web机器人是能够在无须人类干预的情况下自动进行一系列web事务处理的软件程序。

* web爬虫    
	网络爬虫会递归地对各种信息型web站点进行遍历，获取第一个web页面，然后获取该页面指向的其他页面，然后是那些页面的指向页面，以此类推。    
	爬虫开始访问的URL初始集合被称为根集，根集的挑选应该从足够多的不同的站点中去选取，好的根集通常包含一些大的流行站点。    
	爬虫在web上移动时会不停地对HTML页面进行解析，提取出其中的链接并添加到需要爬行的链接列表中去，也需要将相对URL转换为绝对形式。    

	避免环路的出现导致暂停或减缓爬虫的爬行进程，概括来说环路对爬虫的危害分为以下三点：   
		1. 使得未经良好设计的爬虫不停兜圈子，把时间耗费在获取相同的页面上，浪费网络宽带，也无法获取其他页面   
		2. 爬虫不断获取相同页面也会对web服务器造成打击，阻止真实用户访问这个站点   
		3. 爬虫应用程序会被大量重复的内容充斥而变的毫无用处。

	由于web上URL的数量庞大，这要求爬虫具有高效的搜索速度和存储管理：    
		1. 树和散列表    
		2. 有损的存在位图    
		3. 检查点    
		4. 分类

	URL别名：两个URL看起来不一样但实际指向同一资源。URL别名会导致爬虫无法识别页面是否是已访问过的页面，而造成回路，因此大多数机器人都会试图将URL进行规范化：    
		1. 如果没有指定端口，则加上默认端口80    
		2. 将所有转义符%XX都转化为等价字符    
		3. 删除#标签

	一些常用的网络爬虫技术：    
		1. 规范化URL   
		2. 广度优先的爬行   
		3. 节流   
		4. 限制URL的大小   
		5. URL站点黑名单   
		6. 模式检测   
		7. 内容指纹   
		8. 人工监视

* 机器人HTTP

	* 首部	
	
		大部分机器人倾向于支持最小的HTTP集，但建议提供如下首部：   

		* User-Agent：发起请求的机器人名字
		* From：提供机器人的用户/管理者的Email
		* Accept：可接受的媒体类型
		* Referer：提供包含当前请求URL的文档的URL

	* 虚拟主机：HTTP1.1要求爬虫提供Host首部
	* 条件请求
